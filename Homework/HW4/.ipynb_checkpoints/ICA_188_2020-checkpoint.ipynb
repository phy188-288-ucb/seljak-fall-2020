{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2 - Solving the cocktail party problem with ICA\n",
    "\n",
    "\"Independent component analysis was originally developed to deal with problems that are closely related to the cocktail-party problem. The goal is to find a linear representation of nongaussian data so that the components are statistically independent, or as independent as possible. Such a representation seems to capture the essential structure of the data in many applications, including feature extraction and signal separation.\" More details on ICA can be found in https://www.cs.helsinki.fi/u/ahyvarin/papers/NN00new.pdf\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we take the mixed sounds and images, and apply ICA tn them to separate the sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> <i> 1. Read the 3 sound files, and plot them as a function of time.  (In order to better see the features, you may plot them with some offsets.) </i></span> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs, data1 = wavfile.read('mix_sound1.wav')\n",
    "fs, data2 = wavfile.read('mix_sound2.wav')\n",
    "fs, data3 = wavfile.read('mix_sound3.wav')\n",
    "#fs is the sample rate, i.e., how many data points in one second.\n",
    "\n",
    "data = np.float64(np.c_[data1, data2, data3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "...\n",
    "\n",
    "plt.xlabel('Time [second]')\n",
    "plt.ylabel('Sound signal + offset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> <i> 2. Now run the following cells and play the sounds. </i></span> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio('mix_sound1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio('mix_sound2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio('mix_sound3.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tell there are 3 signals mixed in these sounds. You can consider these sounds as recorded by 3 different recorders that have different distrance to the 3 sources. In orther words,\n",
    "<br><br>\n",
    "\\begin{equation}\n",
    " \\bf X = A S + \\mu \\tag{1}\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "where $\\boldsymbol X$ is a vector of these 3 sounds, $\\boldsymbol S$ is a vector of 3 signals, $\\boldsymbol \\mu$ is a vector of the mean of $\\boldsymbol X$, and $\\boldsymbol A$ is the mixing matrix. \n",
    "<br><br>\n",
    "Next, using the sklearn's fastICA module, we will separate the signals from these sounds.\n",
    "<br><br>\n",
    "(1) Define the fastICA model:\n",
    "\n",
    "&nbsp; **ica = FastICA(algorithm='parallel')**\n",
    "\n",
    "(2) Using \"fit_transform,\" fit the model with the data and obtain the signals\n",
    "\n",
    "&nbsp; **S = ica.fit_transform(data)**\n",
    "\n",
    "<span style=\"color:blue\"> <i> 3. Find the 3 signals in the sound files. Plot the signals. (Again, you may plot them with some offsets.)</i></span> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "...\n",
    "\n",
    "plt.xlabel('Time [second]')\n",
    "plt.ylabel('Sound signal + offset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find the amplitude of the signals is very small. This is because fastICA whitens the data first before applying ICA, so that the covariance matrix of the signals is I. We can amplify the signals by multiplying them with a large number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> <i> 4. Now let's save the signals as wav files and play the sounds. </i></span> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Amp = 1e6\n",
    "\n",
    "wavfile.write('signal_sound1.wav', fs, np.int16(Amp*S[:,0]))\n",
    "wavfile.write('signal_sound2.wav', fs, np.int16(Amp*S[:,1]))\n",
    "wavfile.write('signal_sound3.wav', fs, np.int16(Amp*S[:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can reconstruct the mixed sounds with the signals. The mixing matrix is given by ica.mixing_, and the mean of the data is given by ica.mean_. Note that the $X$ and $S$ from equation (1) are matrices of shape (Nsignal, Nsample), but the data and the signal you get from FastICA are matrices of shape (Nsample, Nsignal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> <i> 5. Reconstruct the sounds from the source signal, and show that the reconstruct sounds is very close to the given sounds using np.allclose</i></span> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mixing matrix\n",
    "A = ...\n",
    "mu = ...\n",
    "\n",
    "X = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (np.allclose(X, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> <i> 6. The ICA requires the data to be centered and whitened. The FastICA module from sklearn does the data centering and whitening automatically. Now let's disable the data preprocessing in FastICA by ica = FastICA(whiten=False), and then redo the analysis in part 3 and 4. Plot and play the sounds. Does ICA work without data preprocessing?</i></span> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "...\n",
    "\n",
    "plt.xlabel('Time [second]')\n",
    "plt.ylabel('Sound signal + offset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> <i> 7. The principal companent analysis (PCA) also tries to interpret the underlying structure of the data by decomposing the data into linear combinations of the principal components. Now let's apply PCA to the sounds and see if the signals are cleanly separated in the principal components. Plot the principal components, save them as wav files and play the sounds. How does it compares to Part 3 and 4? </i></span> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "...\n",
    "\n",
    "plt.xlabel('Time [second]')\n",
    "plt.ylabel('Sound signal + offset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at another example. Suppose now we have some linearly mixed images, and we are going to find the original photos with ICA. (This example is from https://github.com/vishwajeet97/Cocktail-Party-Problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> <i> 8. Load in photos, and plot them. </i></span> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img1=mpimg.imread('unos.jpg')\n",
    "img2=mpimg.imread('dos.jpg')\n",
    "img3=mpimg.imread('tres.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imag is a 2D array. You will need to flatten the data for the following analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> <i> 9. Redo the analysis in part 3 and 4. Separate the original photos and plot them. Note that the sign of the signals recovered by ICA may not be correct, so you probably need to multiply the photos by -1. </i></span> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the original photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICA algorithm tries to find the most non-Gaussian directions of given data. FastICA uses the KL divergence between the data and standard Gaussian (negentropy) to charactrize the non-Gaussianity. Another way to measure non-Gaussianity is to use the Wasserstein distance between the data and standard Gaussian. In 1D, the Wasserstein distance, also called earth mover's distance, has a closed form solution using Cumulative Distribution Function (CDF). Below we provide you the code for doing ICA using Wasserstein distance. The code searches for the most non-Gaussian directions by maximizing the Wasserstein distance between the data and Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> <i> 10. Perform ICA on the mixed photos from Q9 (do the following steps) </i></span> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Whitens the data with sklearn.decomposition.PCA(whiten=True)\n",
    "2. Run ICA with Wasserstein distance: $A$ = ICA_Wasserstein($X_{\\mathrm{whiten}}$)\n",
    "3. Recover the Signal S from the whitened data and mixing matrix $A$. Note that $\\mu=0$ because of the whitening, and the shape of $X$ of equation (1) is (Nsignal, Nsample).\n",
    "4. Plot the signals (original photos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "def Percentile(input, percentiles):\n",
    "    \"\"\"\n",
    "    Find the percentiles of a tensor along the last dimension.\n",
    "    Adapted from https://github.com/aliutkus/torchpercentile/blob/master/torchpercentile/percentile.py\n",
    "    \"\"\"\n",
    "    percentiles = percentiles.double()\n",
    "    in_sorted, in_argsort = torch.sort(input, dim=-1)\n",
    "    positions = percentiles * (input.shape[-1]-1) / 100\n",
    "    floored = torch.floor(positions)\n",
    "    ceiled = floored + 1\n",
    "    ceiled[ceiled > input.shape[-1] - 1] = input.shape[-1] - 1\n",
    "    weight_ceiled = positions-floored\n",
    "    weight_floored = 1.0 - weight_ceiled\n",
    "    d0 = in_sorted[..., floored.long()] * weight_floored\n",
    "    d1 = in_sorted[..., ceiled.long()] * weight_ceiled\n",
    "    result = d0+d1\n",
    "    return result\n",
    "\n",
    "\n",
    "def SlicedWassersteinDistanceG(x, pg, q, p, perdim=True):\n",
    "    if q is None:\n",
    "        px = torch.sort(x, dim=-1)[0]\n",
    "    else:\n",
    "        px = Percentile(x, q)\n",
    "\n",
    "    if perdim:\n",
    "        WD = torch.mean(torch.abs(px-pg) ** p)\n",
    "    else:\n",
    "        WD = torch.mean(torch.abs(px-pg) ** p, dim=-1)\n",
    "    return WD\n",
    "\n",
    "\n",
    "def SWD_prepare(Npercentile=100, device=torch.device(\"cuda:0\"), gaussian=True):\n",
    "    start = 50 / Npercentile\n",
    "    end = 100-start\n",
    "    q = torch.linspace(start, end, Npercentile, device=device)\n",
    "    if gaussian:\n",
    "        pg = 2**0.5 * torch.erfinv(2*q/100-1)\n",
    "        return q, pg\n",
    "\n",
    "    \n",
    "def maxSWDdirection(x, x2='gaussian', n_component=None, maxiter=200, Npercentile=None, p=2, eps=1e-6):\n",
    "\n",
    "    #if x2 is None, find the direction of max sliced Wasserstein distance between x and gaussian\n",
    "    #if x2 is not None, find the direction of max sliced Wasserstein distance between x and x2 \n",
    "\n",
    "    if x2 != 'gaussian':\n",
    "        assert x.shape[1] == x2.shape[1]\n",
    "        if x2.shape[0] > x.shape[0]:\n",
    "            x2 = x2[torch.randperm(x2.shape[0])][:x.shape[0]]\n",
    "        elif x2.shape[0] < x.shape[0]:\n",
    "            x = x[torch.randperm(x.shape[0])][:x2.shape[0]]\n",
    "\n",
    "    ndim = x.shape[1]\n",
    "    if n_component is None:\n",
    "        n_component = ndim\n",
    "\n",
    "    q = None\n",
    "    if x2 == 'gaussian':\n",
    "        if Npercentile is None:\n",
    "            q, pg = SWD_prepare(len(x), device=x.device)\n",
    "            q = None\n",
    "        else:\n",
    "            q, pg = SWD_prepare(Npercentile, device=x.device)\n",
    "    elif Npercentile is not None:\n",
    "        q = SWD_prepare(Npercentile, device=x.device, gaussian=False)\n",
    "\n",
    "\n",
    "    #initialize w. algorithm from https://arxiv.org/pdf/math-ph/0609050.pdf\n",
    "    wi = torch.randn(ndim, n_component, device=x.device)\n",
    "    Q, R = torch.qr(wi)\n",
    "    L = torch.sign(torch.diag(R))\n",
    "    w = (Q * L).T\n",
    "\n",
    "    lr = 0.1\n",
    "    down_fac = 0.5\n",
    "    up_fac = 1.5\n",
    "    c = 0.5\n",
    "\n",
    "    #algorithm from http://noodle.med.yale.edu/~hdtag/notes/steifel_notes.pdf\n",
    "    #note that here w = X.T\n",
    "    #use backtracking line search\n",
    "    w1 = w.clone()\n",
    "    w.requires_grad_(True)\n",
    "    if x2 == 'gaussian':\n",
    "        loss = -SlicedWassersteinDistanceG(w @ x.T, pg, q, p)\n",
    "    else:\n",
    "        loss = -SlicedWassersteinDistance(w @ x.T, w @ x2.T, q, p)\n",
    "    loss1 = loss\n",
    "    for i in range(maxiter):\n",
    "        GT = torch.autograd.grad(loss, w)[0]\n",
    "        w.requires_grad_(False)\n",
    "        WT = w.T @ GT - GT.T @ w\n",
    "        e = - w @ WT #dw/dlr\n",
    "        m = torch.sum(GT * e) #dloss/dlr\n",
    "\n",
    "        lr /= down_fac\n",
    "        while loss1 > loss + c*m*lr:\n",
    "            lr *= down_fac\n",
    "            if 2*n_component < ndim:\n",
    "                UT = torch.cat((GT, w), dim=0).double()\n",
    "                V = torch.cat((w.T, -GT.T), dim=1).double()\n",
    "                w1 = (w.double() - lr * w.double() @ V @ torch.pinverse(torch.eye(2*n_component, dtype=torch.double, device=x.device)+lr/2*UT@V) @ UT).to(torch.get_default_dtype())\n",
    "            else:\n",
    "                w1 = (w.double() @ (torch.eye(ndim, dtype=torch.double, device=x.device)-lr/2*WT.double()) @ torch.pinverse(torch.eye(ndim, dtype=torch.double, device=x.device)+lr/2*WT.double())).to(torch.get_default_dtype())\n",
    "\n",
    "            w1.requires_grad_(True)\n",
    "            if x2 == 'gaussian':\n",
    "                loss1 = -SlicedWassersteinDistanceG(w1 @ x.T, pg, q, p)\n",
    "            else:\n",
    "                loss1 = -SlicedWassersteinDistance(w1 @ x.T, w1 @ x2.T, q, p)\n",
    "\n",
    "        if torch.max(torch.abs(w1-w)) < eps:\n",
    "            w = w1\n",
    "            break\n",
    "\n",
    "        lr *= up_fac\n",
    "        loss = loss1\n",
    "        w = w1\n",
    "    if x2 == 'gaussian':\n",
    "        WD = SlicedWassersteinDistanceG(w @ x.T, pg, q, p, perdim=False)\n",
    "    else:\n",
    "        WD = SlicedWassersteinDistance(w @ x.T, w @ x2.T, q, p, perdim=False)\n",
    "    return w.T, WD**(1/p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ICA_Wasserstein(x):\n",
    "    \n",
    "    A, WD = maxSWDdirection(torch.tensor(x, dtype=torch.float32))\n",
    "        \n",
    "    return A.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Whiten the data\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ICA\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recover S\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the original photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
