{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 8\n",
    "\n",
    "## <em> Interpolation, Resampling Methods, and Gaussian Processes</em>\n",
    "<br>\n",
    "This notebook is arranged in cells. Texts are usually written in the markdown cells, and here you can use html tags (make it bold, italic, colored, etc). You can double click on this cell to see the formatting.<br>\n",
    "<br>\n",
    "The ellipsis (...) are provided where you are expected to write your solution but feel free to change the template (not over much) in case this style is not to your taste. <br>\n",
    "<br>\n",
    "<em>Hit \"Shift-Enter\" on a code cell to evaluate it.  Double click a Markdown cell to edit. </em><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "#For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting Google Drive locally\n",
    "Mount your Google Drive on your runtime using an authorization code.\n",
    "\n",
    "Note: When using the 'Mount Drive' button in the file browser, no authentication codes are necessary for notebooks that have only been edited by the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1 - Supernova revisited\n",
    "\n",
    "In this homework, we use a compilation of supernovae data to show that the expansion of the universe is accelerating, and hence it contains dark energy. This is the Nobel prize winning research in 2011 (https://www.nobelprize.org/nobel_prizes/physics/laureates/2011/), and Saul Perlmutter, a professor of physics at Berkeley, shared a prize in 2011 for this discovery.\n",
    "<br><br>\n",
    "\"The expansion history of the universe can be determined quite easily, using as a “standard candle” any distinguishable class of astronomical objects of known intrinsic brightness that can be identified over a wide distance range. As the light from such beacons travels to Earth through an expanding universe, the cosmic expansion stretches not only the distances between galaxy clusters, but also the very wavelengths of the photons en route. By the time the light reaches us, the spectral wavelength $\\lambda$ has thus been redshifted by precisely the same incremental factor $z = \\Delta \\lambda/\\lambda$ by which the cosmos has been stretched in the time interval since the light left its source. The recorded redshift and brightness of each such object thus provide a measurement of the total integrated expansion of the universe since the time the light was emitted. A collection of such measurements, over a sufficient range of distances, would yield an entire historical record of the universe’s expansion.\" (Saul Perlmutter, http://supernova.lbl.gov/PhysicsTodayArticle.pdf).\n",
    "<br><br>\n",
    "Supernovae emerge as extremely promising candidates for measuring the cosmic expansion. Type I Supernovae arises from the collapse of white dwarf stars when the Chandrasekhar limit is reached. Such nuclear chain reaction occurs in the same way and at the same mass, the brightness of these supernovae are always the same. The relationship between the apparent brightness and distance of supernovae depend on the contents and curvature of the universe.\n",
    "<br><br>\n",
    "We can infer the \"luminosity distance\" $D_L$ from measuring the inferred brightness of a supernova of luminosity $L$. Assuming a naive Euclidean approach, if the supernova is observed to have flux $F$, then the area over which the flux is distributed is a sphere radius $D_L$, and hence <br><br>\n",
    "$$F = \\frac{L}{4\\pi D_L^2}.$$\n",
    "<br>\n",
    "In Big Bang cosmology, $D_L$ is given by:\n",
    "<br><br>\n",
    "$$ D_L = \\frac{\\chi(a)}{a} $$\n",
    "<br>\n",
    "where $a$ is the scale factor ($\\frac{\\lambda_0}{\\lambda} = 1 + z = \\frac{a_0}{a}$, and the quantity with the subscript 0 means the value at present. Note that $a_0 = 1, z_0 = 0$.), and $\\chi$ is the comoving distance, the distance between two objects as would be measured instantaneously today. For a photon, $cdt = a(t)d\\chi$, so $\\chi(t) = c\\int_t^{t_0} \\frac{dt'}{a(t')}$. We can write this in terms of a Hubble factor ($H(t) = \\frac{1}{a}\\frac{da}{dt}$), which tells you the expansion rate: $\\chi(a) = c\\int_a^1 \\frac{da'}{a'^2H(a')} = c\\int_0^z \\frac{dz'}{H(z')}$. (change of variable using $a = \\frac{1}{1+z}$.)\n",
    "<br><br>\n",
    "Using the Friedmann equation (which basically solves Einstein's equations for a homogenous and isotropic universe), we can write $H^2$ in terms of the mass density $\\rho$ of the components in the universe: $H^2(z) = H_0^2[\\Omega_m(1+z)^3 + (1-\\Omega_m)(1+z)^2].$ <br><br>\n",
    "$\\Omega$ is the density parameter; it is the ratio of the observed density of matter and energy in the universe ($\\rho$) to the critical density $\\rho_c$ at which the universe would halt is expansion. So $\\Omega_0$ (again, the subscript 0 means the value at the present) is the total mass and energy density of the universe today, and consequently $\\Omega_0 = \\Omega_{m}$ (matter density parameter today; remember we obtained the best-fit value of this parameter in Project 1?) = $\\Omega_{\\mathrm{baryonoic\\ matter}}$ + $\\Omega_{\\mathrm{dark\\ matter}}$. If $\\Omega_0 < 1$, the universe will continue to expand forever. If $\\Omega_0 > 1$, the expansion will stop eventually and the universe will start to recollapse. If $\\Omega_0 = 1$, then the universe is flat and contains enough matter to halt the expansion but not enough to recollapse it. So it will continue expanding, but gradually slowing down all the time, finally running out of steam only in the infinite future. Even including dark matter in this calculation, cosmologists found that all the matters in the universe only amounts to about a quarter of the required critical mass, suggesting a continuously expanding universe with deceleration. Then, using all this, we can write the luminosity distance in terms of the density parameters: <br><br>\n",
    "$$ D_L = \\frac{\\chi(a)}{a} = c(1+z)\\int_0^z \\frac{dz'}{H(z')} = c(1+z)\\int_0^z \\frac{dz'}{H_0[\\Omega_m(1+z')^3 + (1-\\Omega_m)(1+z')^2]^{1/2}}  $$ <br>\n",
    "$$ = \\frac{2997.92458}{h} (1+z)\\int_0^z \\frac{dz'}{[\\Omega_m(1+z')^3 + (1-\\Omega_m)(1+z')^2]^{1/2}}\\ [unit\\ of\\ Mpc] $$\n",
    "<br>\n",
    "where $H_0 = 100\\cdot h\\ [km\\cdot s^{-1} Mpc^{-1}]$.\n",
    "<br><br>\n",
    "Fluxes can be expressed in magnitudes $m$, where $m = -2.5\\cdot\\mathrm{log}_{10}F$ + const. The distance modulus is $\\mu = m - M$ ($M$ is the absolute magnitude, the value of $m$ if the supernova is at a distance 10pc. Then, we have:\n",
    "<br><br>\n",
    "$$ \\mu = 25 + 5\\cdot \\mathrm{log}_{10}\\Big(D_L\\ [in\\ the\\ unit\\ of \\ Mpc]\\Big)$$\n",
    "<br><br>\n",
    "In this assignment, we use the SCP Union2.1 Supernova (SN) Ia compilation. (http://supernova.lbl.gov/union/)\n",
    "<br><br>\n",
    "First, load the measured data: $z$ (redshift), $\\mu$ (distance modulus), $\\sigma(\\mu)$ (error on distance modulus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"/content/drive/My Drive/P188_288/P188_288_HW8/sn_z_mu_dmu_plow_union2.1.txt\", usecols=range(1,5))\n",
    "# z\n",
    "z_data = data[:,0]\n",
    "# mu\n",
    "mu_data = data[:,1]\n",
    "# error on mu (sigma(mu))\n",
    "mu_err_data = data[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With measurements of the distance modulus $\\mu$, we used Bayesian analysis to estimate the cosmological parameters $w$ and $\\Omega_m$.\n",
    "<br><br>\n",
    "Let us assume that the universe is flat (which is a fair assumption since the CMB measurements indicate that the universe has no large-scale curvature). $\\Omega_0 = \\Omega_m + \\Omega_{DE} = 1$. Then, we do not need to worry about the curvature term:<br><br>\n",
    "$$ D_L = \\frac{\\chi(a)}{a} = c(1+z)\\int_0^z \\frac{dz'}{H(z')} = c(1+z)\\int_0^z \\frac{dz'}{H_0[\\Omega_m(1+z')^3 + (1-\\Omega_m)(1+z')^{3(1+w)}]^{1/2}}  $$ <br>\n",
    "$$ = \\frac{2997.92458}{h} (1+z)\\int_0^z \\frac{dz'}{[\\Omega_m(1+z')^3 + (1-\\Omega_m)(1+z')^{3(1+w)}]^{1/2}}\\ [unit\\ of\\ Mpc] $$<br>\n",
    "where $H_0 = 100\\cdot h\\ [km\\cdot s^{-1} Mpc^{-1}]$.<br><br>\n",
    "Assuming that errors are Gaussian (can be justified by averaging over large numbers of SN; central limit theorem), we calculate the likelihood $L$ as: <br><br>\n",
    "$$ L \\propto \\mathrm{exp}\\Big( -\\frac{1}{2} \\sum_{i = 1}^{N_{\\mathrm{SN}}} \\frac{[\\mu_{i,\\ data}(z_i) - \\mu_{i,\\ model}(z_i, \\Omega_m, w)]^2}{\\sigma(\\mu_i)^2} \\Big) $$\n",
    "<br>\n",
    "where $z_i, \\mu_i, \\sigma(\\mu_i)$ are from the measurements, and we compute $\\mu_{model}$ as a function of $z, \\Omega_m, w$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, assume that the universe is flat, and $w = -1$ (dark energy is $\\Lambda$.) We call this flat $\\Lambda$CDM cosmology. By fixing $h$ and $w$, $D_L = D_L(z, \\Omega_m)$.\n",
    "<br><br>\n",
    "First, I precalculated $D_L$ for $h = 0.7$ from 2 one-dimensional vectors giving the tabulated values of the parameters $z$ and $\\Omega_m$ in the range $0.01 < z < 1.5$ and $0.01 < \\Omega_m < 1$. We call the tabulated values of $z$ and $\\Omega_m$ as \"z_fit\" (length 200) and \"Om0_fit\" (length 100). Then, \"DL_fit\" is a 2-dimensional grid of tabulated values of $D_L$ (its dimension 200 $\\times$ 100. i.e. $D_L$[i,j] is $D_L$$\\big($$z$ = z_fit[i], $\\Omega_m$ = Om0_fit[j]$\\big)$\n",
    "<br><br>\n",
    "Now using a 2-D spline interpolation, estimate $D_L(z, \\Omega_m)$ for any $z$ and $\\Omega_m$.\n",
    "<br><br>\n",
    "<span style=\"color:blue\"> <i> 1. Using scipy.interpolate.RectBivariateSpline, estimate $D_L(z, \\Omega_m)$ for any $z$ and $\\Omega_m$. Plot $\\mu = 25 + 5\\cdot \\mathrm{log}_{10}(D_L(z, \\Omega_m = 0.3))$ as a function of $z$ on top of the measured data. How does it fit to the data? </i></span>\n",
    "<br><br>\n",
    "(Hint: Let z_spline = RectBivariateSpline(x_fit,y_fit,z_fit). Then, z_spline.ev(x,y) will evaulate the spline at given positions x and y.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DL_fit = np.loadtxt(\"/content/drive/My Drive/P188_288/P188_288_HW8/DL_fit.txt\").T\n",
    "Om0_fit = np.loadtxt(\"/content/drive/My Drive/P188_288/P188_288_HW8/Om0_fit.txt\")\n",
    "z_fit = np.loadtxt(\"/content/drive/My Drive/P188_288/P188_288_HW8/z_fit.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import RectBivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,14))\n",
    "\n",
    "...\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(0.01, 1.5)\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('$\\mu$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "Now, run emcee to estimate $\\Omega_m$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You calculated $\\mu$ from the $\\Lambda$CDM model given $z$ and $\\Omega_m$, using $D_L$ from the 2D spline interpolation. Using this result, define a function $\\mu_{model}$ which outputs $\\mu$ from the $\\Lambda$CDM theory model given $z$ and $\\Omega_m$. Then, Dmu[j] = mu_data[j]-mu_model(z_data[j],Omegam), and the log-likelihood is \n",
    "<br><br>\n",
    "$$ \\mathrm{ln}(L) \\approx -\\frac{1}{2} \\sum_{i = 1}^{N_{\\mathrm{SN}}} \\frac{[\\mu_{i,\\ data}(z_i) - \\mu_{i,\\ model}(z_i, \\Omega_m)]^2}{\\sigma(\\mu_i)^2} = -\\frac{1}{2} \\sum_{i = 1}^{N_{\\mathrm{SN}}} \\frac{Dmu_i^2}{\\sigma(\\mu_i)^2} $$\n",
    "\n",
    "<span style=\"color:blue\"> <i> 2. Define a function for mu_model (mu predicted from theory) and lnL (log-likelihood). Then, (1) Run few parallel sequences of Metropolis algorithm simulations using the package \"emcee\". (2) Print your constraints on $\\Omega_m$. (3) Plot 1-d posterior of $\\Omega_m$. Make sure that your chains have converged.</i></span>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use a <b>Boostrap</b> resampling method to estimate the posterior of $\\Omega_m$ and $w$.\n",
    "<br><br>\n",
    "Suppose that we have 10 measurements of $x$: [3.7, 3.2, 3.3, 3.1, 3.2, 3.5, 2.9, 3.4, 3.0, 3.1]. Now, randomly take 5 samples of 10 data measurements \"with replacement.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After bootstrap re-sampling\n",
      "[[ 2.9  3.1  3.   3.   3.2  3.1  3.3  3.5  3.4  2.9]\n",
      " [ 3.4  3.3  3.   3.2  3.1  3.1  3.5  3.1  3.1  3.4]\n",
      " [ 3.2  3.2  3.2  3.2  3.7  3.1  3.2  3.2  3.3  3. ]\n",
      " [ 2.9  2.9  2.9  3.2  3.   3.2  3.5  3.1  3.7  3.5]\n",
      " [ 3.2  2.9  3.2  3.2  3.3  3.3  3.2  3.2  3.4  3.7]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([3.7, 3.2, 3.3, 3.1, 3.2, 3.5, 2.9, 3.4, 3.0, 3.1])\n",
    "\n",
    "num_samples = 5\n",
    "len_x = len(x)\n",
    "idx = np.random.randint(0, len_x, (num_samples, len_x))\n",
    "print(\"After bootstrap re-sampling\")\n",
    "print(x[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you wish to see the probability distribution of $\\bar{x}$. Then, take 100 samples using bootstrap and plot the histogram of $\\bar{x}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEMCAYAAADK231MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105cf1e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 1000\n",
    "len_x = len(x)\n",
    "idx = np.random.randint(0, len_x, (num_samples, len_x))\n",
    "x_bar = np.mean(x[idx], axis = 1)\n",
    "plt.hist(x_bar,bins=20)\n",
    "plt.xlabel(r'$\\bar{x}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br><br>\n",
    "<span style=\"color:blue\"> <i> 3. Use a bootstrap resampling technique to estimate the posteriors of $\\Omega_m$ and $w$. Plot their 1-d posteriors (histograms). Take 200 bootstrap samples (or more - obviously you will get a better estimate with a greater number of samples) of supernova distance modulus measurements. </i></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2 - Back to Quasar (Continued from HW6 - Problem 2 - Part 7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "#For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "wavelength = np.loadtxt(\"/content/drive/My Drive/P188_288/P188_288_HW8/HW5_Problem2_wavelength_300.txt\")\n",
    "X = np.loadtxt(\"/content/drive/My Drive/P188_288/P188_288_HW8/HW5_Problem2_QSOspectra_300.txt\")\n",
    "ivar = np.loadtxt(\"/content/drive/My Drive/P188_288/P188_288_HW8/HW5_Problem2_ivar_flux_300.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "The following analysis is based on https://arxiv.org/pdf/1605.04460.pdf.\n",
    "<br><br>\n",
    "In HW6, we reconstruct the QSO spectra from the noisy data. This reconstructed spectra is closer to the true spectra of QSO. Note that in reality, the true spectra can never be directly observed, both due to measurement error and due to absorption by intervening matter along the line of sight. So we wish to perform inference about the true spectra of QSO using a non-parametric technique called <b>Gaussian processes (GP)</b>. We henceforth call the measured spectra as $y(\\lambda)$ and the true spectra as $f(\\lambda)$ (where $\\lambda$ refers to wavelength).\n",
    "<br><br>\n",
    "A gaussian process is fully specified by its first two central moments: a mean function $\\mu(\\lambda)$ and a covariance function $K(\\lambda, \\lambda')$: <br><br>\n",
    "$$ \\mu(\\lambda) = \\mathbb{E}[f(\\lambda)\\ \\vert\\ \\lambda] $$<br>\n",
    "$$ K(\\lambda, \\lambda') = \\mathrm{cov}[f(\\lambda), f(\\lambda')\\ \\vert\\ \\lambda, \\lambda'] $$.\n",
    "<br>\n",
    "In this problem, we can derive the posterior distribution of $f$ conditioned on the observed values of $y$: <br><br>\n",
    "$$ p(f^*\\ \\vert\\ \\lambda^*, \\lambda, y, \\sigma(\\lambda)^2) = \\mathcal{N}(f^*\\ \\vert\\ \\mu_{f|y}(\\lambda^*), K_{f|y}(\\lambda^*, \\lambda^{*,})) $$\n",
    "<br>\n",
    "where $\\mathcal{N}(f\\ \\vert\\ \\mu, K)$ is a multivariate Gaussian given by: <br>\n",
    "$$ \\mathcal{N}(f\\ \\vert\\ \\mu, K) = \\frac{1}{\\sqrt{(2\\pi)^d \\mathrm{det}K}} \\mathrm{exp}\\big(-\\frac{1}{2}(f-\\mu)^TK^{-1}(f-\\mu)\\big) $$<br>\n",
    "where $d$ is the dimension of $f$.\n",
    "<br><br><br><br>\n",
    "In other words, for the QSO $i$, the measured spectra $y$ is $X_{row\\ i}$. Then, we can compute the posterior distribution of $f$ given $X_{row\\ i}$ as:\n",
    "<br><br>\n",
    "$$ \\mu + \\mathcal{N}\\big(f\\ \\big\\vert\\ \\mu_{f|X_{row\\ i}}, K_{f|X_{row\\ i}}\\big) $$\n",
    "<br>\n",
    "where $\\mu$ is given by:\n",
    "<br><br>\n",
    "$ \\mu$ $ =\n",
    "    \\begin{bmatrix}\n",
    "        \\overline{x}_1 & \\overline{x}_2 & \\dots  &  \\overline{x}_{824} \\\\\n",
    "    \\end{bmatrix}.$\n",
    "<br><br>\n",
    "The mean function $\\mu_{f|X_{row\\ i}}$ and the covariance function $K_{f|X_{row\\ i}}$ are defined as:<br><br>\n",
    "$$ \\mu_{f|X_{row\\ i}} = \\mu\\ +\\ K(K + V)^{-1}(X_{row\\ i} - \\mu)  $$<br>\n",
    "$$ K_{f|X_{row\\ i}} = K - K(K + V)^{-1}K$$\n",
    "<br>\n",
    "where $K = \\phi \\phi^T$ (We can use $\\phi$ from Part 7, Problem 2, HW6. $\\phi$ is a matrix of eigenvectors, its dimension is \"nLambda\" x \"nEigvec\"). <br><br>$V$ is a diagonal matrix whose entries are $\\sigma(\\lambda)^2$ e.g. for the QSO $i$, $V$ = np.diag(1/ivar[i,:]).\n",
    "<br><br>\n",
    "Finally, we can plot $f(\\lambda)$ by sampling from $\\mathcal{N}\\big(f\\ \\big\\vert\\ \\mu_{f|X_{row\\ i}}, K_{f|X_{row\\ i}}\\big)$.\n",
    "<br><br>\n",
    "<span style=\"color:blue\"> <i> 1. For any two spectra, plot $f(\\lambda)$ using Gaussian processes. You can use np.random.multivariate_normal (https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.multivariate_normal.html) to sample from a multivariate Gaussian. Plot the original spectra in the same figure for comparison. </i></span> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
